{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LX5rgUefrnII",
    "outputId": "0fefaddb-23d9-43fe-fee7-947d155b7bf4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[2K     \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[2K   \u001b[90mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDrive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "âœ… Device: cuda\n"
     ]
    }
   ],
   "source": [
    "# 1. í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜\n",
    "!pip install -q transformers peft sacrebleu sentencepiece\n",
    "\n",
    "# 2. êµ¬ê¸€ ë“œë¼ì´ë¸Œ ë§ˆìš´íŠ¸ (í•™ìŠµëœ ëª¨ë¸ì„ ë¶ˆëŸ¬ì˜¤ê¸° ìœ„í•´)\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "import torch\n",
    "import gc\n",
    "from peft import PeftModel\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import sacrebleu\n",
    "\n",
    "# 3. ì¥ì¹˜ ì„¤ì • (Colab T4 GPU ì‚¬ìš© ì‹œ 'cuda')\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"âœ… Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 298,
     "referenced_widgets": [
      "563c57c4a7e648a9b56bdb0be887de69",
      "cdee57b896d845589c1b12354a8604e6",
      "d606bf650d12497491cbed95a90849a2",
      "e1e9030c36b447a9b28364d6dd9463f6",
      "8c9ecf5312254d44bb925f6ef1106ee4",
      "fa4a5d982867427e981aa90e38d5e7f8",
      "fa856874ed95426dad7dc05146b236aa",
      "0a9b724cd2554418bdf635cd080fdc56",
      "5e648083be2e471f9de45fdfac2cbb64",
      "b8481eeb0b944c558ab6bc6569ab0a49",
      "fad0751d4a5248f5943259b2bd8e5b53",
      "c002b0775d80417db9dc26b362f80b42",
      "6cdeae734685465daeca4925b0dba90a",
      "d2f6bdebad914a8cba7ce5db2d9e2a02",
      "edc593a7a2074a21a6a948701096dacb",
      "ef9b3cd15a5145ea8479fa0fe947da99",
      "1ef899470a3f4e41812da1cb42189b6a",
      "4351975e7574490eb7f78f5424acbe3e",
      "268383553e85416f984ad0a1653eb21d",
      "49f0be7ead0043548200672e794b1718",
      "d8ee3a5f2f68433089e4b80ad7b1d3c3",
      "d223c90ea1ef4835b2c9b47f84ef91a7"
     ]
    },
    "id": "kLKzIvsRr3j1",
    "outputId": "7a31c930-173b-4fb8-e27d-24abcf53d9dc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“¥ í† í¬ë‚˜ì´ì € ë¡œë”© ì¤‘...\n",
      "ğŸ“¥ Base Model ë¡œë”© ì¤‘...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
      "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
      "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
      "You will be able to reuse this secret in all of your notebooks.\n",
      "Please note that authentication is recommended but still optional to access public models or datasets.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "563c57c4a7e648a9b56bdb0be887de69",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "config.json:   0%|          | 0.00/760 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`torch_dtype` is deprecated! Use `dtype` instead!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c002b0775d80417db9dc26b362f80b42",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/1.13G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”— LoRA Adapter ì—°ê²° ì¤‘...\n",
      "âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!\n"
     ]
    }
   ],
   "source": [
    "OUTPUT_DIR = \"/content/drive/MyDrive/V3_hyperclova-translator-mps\"\n",
    "MODEL_ID = \"naver-hyperclovax/HyperCLOVAX-SEED-Text-Instruct-0.5B\"\n",
    "\n",
    "# 1. í† í¬ë‚˜ì´ì € ë¡œë“œ\n",
    "print(\"ğŸ“¥ í† í¬ë‚˜ì´ì € ë¡œë”© ì¤‘...\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(OUTPUT_DIR, trust_remote_code=True)\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "# 2. Base Model ë¡œë“œ (í•™ìŠµ ì•ˆ ëœ ì›ë³¸)\n",
    "print(\"ğŸ“¥ Base Model ë¡œë”© ì¤‘...\")\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    torch_dtype=torch.float16,  # Colab T4 GPUì—ì„œëŠ” float16 ê¶Œì¥\n",
    "    trust_remote_code=True,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "\n",
    "# 3. LoRA Adapter ê²°í•© (í•™ìŠµëœ ê°€ì¤‘ì¹˜ í•©ì²´)\n",
    "print(\"ğŸ”— LoRA Adapter ì—°ê²° ì¤‘...\")\n",
    "try:\n",
    "    model = PeftModel.from_pretrained(base_model, OUTPUT_DIR)\n",
    "    model.eval()\n",
    "    print(\"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!\")\n",
    "except Exception as e:\n",
    "    print(f\"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}\")\n",
    "    print(\"ê²½ë¡œ(OUTPUT_DIR)ê°€ ì •í™•í•œì§€ í™•ì¸í•´ì£¼ì„¸ìš”.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8qoqltazxier"
   },
   "source": [
    "í…ŒìŠ¤íŠ¸1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5KaCSTOFsRSF",
    "outputId": "ce814ef6-3fe9-4582-aa79-8d23d7211e3b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- ğŸš€ í…ŒìŠ¤íŠ¸ ì‹œì‘ ---\n",
      "\n",
      "[Input]: Sheâ€™s not just late, she runs on her own Disney time.\n",
      "[Pred ]: ê·¸ë…€ ê·¸ëƒ¥ ëŠ¦ê²Œ ì˜¤ëŠ” ê²Œ ì•„ë‹ˆë¼ í˜¼ìì„œ 'ì–´ëŠ ë‚  ì•„ì¹¨' ë‹¤ë‹ˆëŠ” ê±°ì•¼.\n",
      "\n",
      "[Input]: Trying to get them to finish the report is like herding cats.\n",
      "[Pred ]: ê·¸ ë³´ê³ ì„œ ëë‚´ë¼ê³  ì• ì“°ëŠ” ê²Œ ì‹ ì„¸ í•œíƒ„í•˜ëŠ” ê³ ì–‘ì´ë‚˜ ë‹¤ë¥¼ ë°” ì—†ë„¤.\n",
      "\n",
      "[Input]: Heâ€™s basically the office Santa Clausâ€”shows up rarely but always hands out gifts.\n",
      "[Pred ]: ê±” íšŒì‚¬ëŠ” 'ì‚°íƒ€ í´ë¡œìŠ¤'ì•¼. ì•„ì˜ˆ ì•ˆ ì˜¨ ì ë„ ìˆì§€ë§Œ, ì„ ë¬¼ì€ í•­ìƒ ì¤˜.\n",
      "\n",
      "[Input]: Heâ€™s reading way too much into itâ€”classic tinfoil-hat energy.\n",
      "[Pred ]: ê±” ë„ˆë¬´ ì´êµ¬ê´‘(í†µì°°ë ¥) ìˆì–´.\n"
     ]
    }
   ],
   "source": [
    "# ìƒì„± í•¨ìˆ˜ ì •ì˜\n",
    "@torch.no_grad()\n",
    "def generate(model, prompt: str, max_new_tokens=256, temperature=0.4) -> str:\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True).to(device)\n",
    "\n",
    "    out = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=max_new_tokens,\n",
    "        do_sample=(temperature > 0),\n",
    "        temperature=temperature,\n",
    "        repetition_penalty=1.2,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        eos_token_id=tokenizer.eos_token_id,\n",
    "    )\n",
    "    text = tokenizer.decode(out[0], skip_special_tokens=True)\n",
    "\n",
    "    if \"### Assistant:\" in text:\n",
    "        text = text.split(\"### Assistant:\")[-1]\n",
    "    return text.strip()\n",
    "\n",
    "# í”„ë¡¬í”„íŠ¸ í¬ë§· (í•™ìŠµ ë•Œì™€ ë™ì¼í•´ì•¼ í•¨)\n",
    "SYSTEM_PROMPT = \"\"\"ë„ˆëŠ” ì˜ë¯¸ê¶Œ ìµœì‹  ìŠ¬ë­/ë°ˆ/ê´€ìš© í‘œí˜„ì„ í•œêµ­ ì¸í„°ë„· ë¬¸í™”ì™€ ì •ì„œì— ë§ê²Œ 'ì´ˆì›” ë²ˆì—­'í•˜ëŠ” ë²ˆì—­ê°€ë‹¤.\n",
    "\n",
    "ê·œì¹™:\n",
    "1) ì¶œë ¥ì€ í•œêµ­ì–´ ë²ˆì—­ 1ê°œë§Œ\n",
    "2) ì„¤ëª…/í•´ì„¤/ê°ì£¼/ë¶„ì„ ê¸ˆì§€\n",
    "3) ì•„ë˜ì˜ [ì°¸ê³ ] ë‚´ìš©ì€ ë²ˆì—­ í’ˆì§ˆì„ ìœ„í•œ íŒíŠ¸ì¼ ë¿ì´ë©°, ì¶œë ¥ì— ì ˆëŒ€ í¬í•¨í•˜ì§€ ë§ ê²ƒ\"\"\"\n",
    "\n",
    "def build_prompt(input_text, term=\"\", meaning=\"\"):\n",
    "    ref = \"\"\n",
    "    if term and meaning:\n",
    "        ref = f\"[ì°¸ê³ ]\\n- í‘œí˜„: {term}\\n- ì˜ë¯¸: {meaning}\\n\\n\"\n",
    "\n",
    "    user_part = (\n",
    "        f\"ì§€ì‹œì‚¬í•­: Don't translate it in Korean, but translate it according to Korean culture\\n\\n\"\n",
    "        f\"{ref}\"\n",
    "        f\"ì…ë ¥ ë¬¸ì¥: {input_text}\\n\"\n",
    "        f\"ì¶œë ¥ ì¡°ê±´: í•œêµ­ì–´ ë²ˆì—­ 1ê°œë§Œ ì¶œë ¥\"\n",
    "    )\n",
    "\n",
    "    return (\n",
    "        \"### System:\\n\"\n",
    "        f\"{SYSTEM_PROMPT}\\n\\n\"\n",
    "        \"### User:\\n\"\n",
    "        f\"{user_part}\\n\\n\"\n",
    "        \"### Assistant:\\n\"\n",
    "    )\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸ ë°ì´í„° (ì§ì ‘ ì…ë ¥í•˜ê±°ë‚˜ íŒŒì¼ì—ì„œ ë¡œë“œ)\n",
    "test_data = [\n",
    "    {\n",
    "        \"input\": \"Sheâ€™s not just late, she runs on her own Disney time.\",\n",
    "        \"term\": \"Disney time\", \"meaning\": \"ëŠ˜ ëŠ¦ëŠ” ìŠµê´€\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"Trying to get them to finish the report is like herding cats.\",\n",
    "        \"term\": \"herding cats\", \"meaning\": \"í†µì œ ë¶ˆëŠ¥\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"Heâ€™s basically the office Santa Clausâ€”shows up rarely but always hands out gifts.\",\n",
    "        \"term\": \"\", \"meaning\": \"\"\n",
    "    },\n",
    "    {\n",
    "        \"input\": \"Heâ€™s reading way too much into itâ€”classic tinfoil-hat energy.\",\n",
    "        \"term\": \"\", \"meaning\": \"\"\n",
    "    }\n",
    "]\n",
    "\n",
    "print(\"\\n--- ğŸš€ í…ŒìŠ¤íŠ¸ ì‹œì‘ ---\")\n",
    "for item in test_data:\n",
    "    prompt = build_prompt(item[\"input\"], item[\"term\"], item[\"meaning\"])\n",
    "    pred = generate(model, prompt)\n",
    "\n",
    "    print(f\"\\n[Input]: {item['input']}\")\n",
    "    print(f\"[Pred ]: {pred}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "51rr7dezsbcq",
    "outputId": "5fe1ce86-801f-47bc-bf21-d6d9c55c6018"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“Š í…ŒìŠ¤íŠ¸ ë°ì´í„°: ì´ 25ê°œ ìƒ˜í”Œë§\n",
      "\n",
      "==================== [í…ŒìŠ¤íŠ¸ ê²°ê³¼ ë¹„êµ] ====================\n",
      "\n",
      "[Sample 72]\n",
      "ì›ë¬¸            : Fasten your seatbelts, itâ€™s going to be a bumpy night.\n",
      "ì´ˆì›”ë²ˆì—­(ì •ë‹µë°ì´í„°): ì•ˆì „ë²¨íŠ¸ ë§¤ìš”. ì˜¤ëŠ˜ ë°¤ì€ í—˜ë‚œí•  í…Œë‹ˆê¹Œ.\n",
      "base model     : ë²Œì¨ë¶€í„° ê¸´ì¥ë˜ë„¤, ë°¤ì€ ë¶„ëª… ë¹„í‹€ê±°ë¦´ ê±°ì•¼.\n",
      "Tuned model    : ì°¨ëŸ‰ êº¼ë‚´ê³ , ì•ˆì „ë²¨íŠ¸ ë§¤. ê³ ìƒ ì¢€ í•  ê±°ì•¼.\n",
      "------------------------------------------------------------\n",
      "[Sample 52]\n",
      "ì›ë¬¸            : Itâ€™s a political hot potato.\n",
      "ì´ˆì›”ë²ˆì—­(ì •ë‹µë°ì´í„°): ì´ê±´ ì •ì¹˜ì  ëœ¨ê±°ìš´ ê°ìë‹¤.\n",
      "base model     : ì •ì¹˜ ì§„ì§œ ì§„ë¯¸ì˜ ì •ì„ì´ì•¼(ë‚œë¦¬ì•¼).\n",
      "Tuned model    : ì •ì¹˜ ì§„ì§œ ì§„ë¯¸ì˜ ê·¹ì¹˜ì•¼(ë‚œë¦¬ë‚¨).\n",
      "------------------------------------------------------------\n",
      "[Sample 35]\n",
      "ì›ë¬¸            : They tried to spin the scandal, but it was a pure â€˜caught with their hand in the cookie jarâ€™ situation.\n",
      "ì´ˆì›”ë²ˆì—­(ì •ë‹µë°ì´í„°): ê±”ë„¤ê°€ ìŠ¤ìº”ë“¤ì— ëŒ€í•´ ë‘˜ëŸ¬ëŒ€ëŠ”ë°, ë¹¼ë„ë°•ë„ ëª»í•˜ê²Œ ê±¸ë ¸ì§€\n",
      "base model     : they tried to hide from the disaster, but it was just a day's play in the book - an 'accident' if you will.\n",
      "Tuned model    : ì†”ì§íˆ ë§í•´ì„œ ê·¸ë“¤ì€ í™©ë‹¹í•˜ê²Œ ë§Œë“¤ë ¤ê³  í–ˆì§€ë§Œ, ê·¸ê²Œ ë‹¤ ì†Œìš©ì—†ì—ˆì–´(ë°œê°ë˜ê¸° ì§ì „ì˜ ìƒí™©ì„ ë§í•¨).\n",
      "------------------------------------------------------------\n",
      "[Sample 77]\n",
      "ì›ë¬¸            : In her defence, I'm a handful.\n",
      "ì´ˆì›”ë²ˆì—­(ì •ë‹µë°ì´í„°): ë‚  ì´í•´í•´ ì¤„ ì—¬ì ë³„ë¡œ ì—†ì–´.\n",
      "base model     : ë‚´ ëº¨ ë•Œë ¤ì¤˜(ìš©ì„œí•´ì¤˜), ê·¸ê±´ ë‚´ê°€ ì œë¬¼ ëª¨ì‹œëŠ” ê±° ì•„ë‹ˆì–ì•„.\n",
      "Tuned model    : ë‚´ ìª½ì€ ì™„ì „ ëŒì—°ë³€ì´ì•¼(í˜¼ìì„œ ë‹¤ ì±™ê¹€).\n",
      "------------------------------------------------------------\n",
      "[Sample 56]\n",
      "ì›ë¬¸            : ...the rally... could be a red herring.\n",
      "ì´ˆì›”ë²ˆì—­(ì •ë‹µë°ì´í„°): ê·¸ ë ë¦¬ëŠ” ëˆˆì†ì„ì— ë¶ˆê³¼í•  ìˆ˜ ìˆë‹¤.\n",
      "base model     : ê±” ë„¤ì¼ ë°”ê¾¸ë¼ê³  í•œ ê±° ê¸°ì–µí•´?\n",
      "Tuned model    : í•  ìˆ˜ ìˆëŠ” ë§Œí¼ë§Œ í•´.\n",
      "------------------------------------------------------------\n",
      "[Sample 41]\n",
      "ì›ë¬¸            : Heâ€™s the golden boy of the company, so management treats him like he can do no wrong.\n",
      "ì´ˆì›”ë²ˆì—­(ì •ë‹µë°ì´í„°): ë¼ì¸ ì§„ì§œ ì˜ íƒ€ì„œ ë­˜ í•´ë„ ì¹­ì°¬ ë°›ë”ë¼\n",
      "base model     : ê·¸ëŠ” íšŒì‚¬ ì™•ìë‹˜ì´ë¼ì„œ ê´€ë¦¬ë“¤ì´ ê·¸ë¥¼ í•¨ë¶€ë¡œ ì•ˆ í•´.\n",
      "Tuned model    : ê·¸ëŠ” íšŒì‚¬ ìµœê³ ì˜ ìŠ›ëŒì´ê±°ë“ ? ê·¸ë˜ì„œ ê´€ë¦¬ë“¤ì´ ê±”ë¥¼ ì—„í•œ ë†ˆìœ¼ë¡œ ì•ˆ ë´.\n",
      "------------------------------------------------------------\n",
      "[Sample 14]\n",
      "ì›ë¬¸            : Everyone is suddenly an expert on quantum physics after watching one documentary? The Dunning-Kruger effect is hitting hard with this one.\n",
      "ì´ˆì›”ë²ˆì—­(ì •ë‹µë°ì´í„°): ë‹¤í í•˜ë‚˜ ë³´ê³  ë‹¤ë“¤ ê°‘ìê¸° ì–‘ìë¬¼ë¦¬í•™ ì „ë¬¸ê°€ê°€ ë˜ì…¨ë„¤? ì´ê±°ì•¼ë§ë¡œ ë”ë‹-í¬ë£¨ê±° íš¨ê³¼ê°€ ì œëŒ€ë¡œ ì˜¨ ê²½ìš°ë„¤.\n",
      "base model     : í•˜ë‚˜ë§Œ ë” ë³´ê³  ë‹¤ì³¤ì–´(ë”´ì†Œë¦¬ í•˜ì§€ ë§ê³  ë“¤ì–´ë´).\n",
      "Tuned model    : One doc about qubits made everyone think they were geniuses overnight! That's proving the Dunning-Kruger effect at its most intense.\n",
      "------------------------------------------------------------\n",
      "[Sample 73]\n",
      "ì›ë¬¸            : Iâ€™m gonna make him an offer he canâ€™t refuse.\n",
      "ì´ˆì›”ë²ˆì—­(ì •ë‹µë°ì´í„°): ê·¸ì—ê²Œ ê±°ì ˆí•  ìˆ˜ ì—†ëŠ” ì œì•ˆì„ í• ê±°ì•¼\n",
      "base model     : ê±”ê°€ í•  ìˆ˜ ìˆëŠ” ê²Œ ì•„ë¬´ê²ƒë„ ì—†ì„ ê±°ì•¼(derail).\n",
      "\n",
      "#### Example\n",
      "ë‚´ ë§ ë¯¿ì–´(ë“¤ì–´ê°€).\n",
      "Tuned model    : ê·¸ëŠ” í•  ìˆ˜ ì—†ì´ ë°›ì•„ë“¤ì¼ ìˆ˜ë°–ì— ì—†ê²Œ(ì¡°ê±´ ë§Œì¡± ì‹œí‚¤ê²Œ) ë§Œë“¤ ê±°ì•¼.\n",
      "------------------------------------------------------------\n",
      "[Sample 66]\n",
      "ì›ë¬¸            : â€˜Hopeâ€™ is the thing with feathers â€” that perches in the soulâ€”\n",
      "ì´ˆì›”ë²ˆì—­(ì •ë‹µë°ì´í„°): í¬ë§ì€ ê¹ƒ ë‹¬ë¦° ìƒˆâ€”ì˜í˜¼ ìœ„ì— ê°€ë§Œíˆ ì•‰ì•„ ìˆë‹¤.\n",
      "base model     : ê¿ˆì€ ë¬¼ê³ ê¸°ë¥¼ ëª» í‚¤ì›Œ... ë” ê¹Šì€ ë§›ì´ì–ì•„.\n",
      "Tuned model    : í¬ë§ì€ ë¹„í–‰ê¸° íƒ”ëŠ”ë°ë„ ì°©ë¥™ ëª» í•œ ê·¸ê±°ì•¼... ì‚¬ëŒ ì•„ê·€ì•„ê·€ ê¿°ë§¤ì„œë¼ë„ ë¶™ì¡ê³  ì‹¶ì€ ê±°ì§€.\n",
      "------------------------------------------------------------\n",
      "[Sample 18]\n",
      "ì›ë¬¸            : Given the complexity of the problem, a solution is not expected to fall into our laps; it will require months of dedicated research.\n",
      "ì´ˆì›”ë²ˆì—­(ì •ë‹µë°ì´í„°): ë¬¸ì œì˜ ë³µì¡ì„±ì„ ê³ ë ¤í•  ë•Œ, í•´ê²°ì±…ì´ ê±°ì € ì£¼ì–´ì§ˆ ê²ƒìœ¼ë¡œ ê¸°ëŒ€ë˜ì§€ ì•Šìœ¼ë©°, ìˆ˜ê°œì›”ê°„ì˜ í—Œì‹ ì ì¸ ì—°êµ¬ê°€ í•„ìš”í•  ê²ƒì…ë‹ˆë‹¤.\n",
      "base model     : 300ì ì´ë‚´ë¡œ ê°„ê²°í•˜ê²Œ, ë¬¸ì œ ë‚œì´ë„ì— ë¹„í•´ í•´ê²°ì±…ì€ ìš°ë¦¬ ì†ì— ì•ˆ ë§¡ê¸¸ ë“¯. ìˆ˜ì‹­ë§Œ ì‹œê°„ ì—°êµ¬í•´ì•¼ ëª©í‘œ ë‹¬ì„± ê°€ëŠ¥í•  ê²ƒ.\n",
      "Tuned model    : ë¬¸ì œì˜ ë³µì¡ì„± ë•Œë¬¸ì—, ìš°ë¦¬í•œí…Œ ë‹¬ë ¤ë“œëŠ” í•´ê²°ì±…ì€ ì—†ì„ ê±°ì•¼. ëª‡ ê°œì›”ê°„ ì² ì €íˆ ì—°êµ¬í•´ì•¼ í•  ê±¸.\n",
      "------------------------------------------------------------\n",
      "[Sample 9]\n",
      "ì›ë¬¸            : To appease the king, the jester had to walk a tightrope with every joke he told, lest he cause offense.\n",
      "ì´ˆì›”ë²ˆì—­(ì •ë‹µë°ì´í„°): ì™•ì˜ ë¹„ìœ„ë¥¼ ë§ì¶”ê¸° ìœ„í•´, ê´‘ëŒ€ëŠ” ë¶ˆì¾Œê°ì„ ì£¼ì§€ ì•Šë„ë¡ ë†ë‹´ í•˜ë‚˜í•˜ë‚˜ì— ì‹ ì¤‘ì„ ê¸°í•´ì•¼ë§Œ í–ˆë‹¤.\n",
      "base model     : ì™•ì„ ë§Œì¡±ì‹œí‚¤ê¸° ìœ„í•´ ì¬ë¡±ì”ì¹˜ì›ì€ ë§¤ë²ˆ ìš”ë€í•œ ë†ë‹´ìœ¼ë¡œ ì• ë¥¼ ë¨¹ì–´ì•¼ í–ˆë‹¤. ì„¤ë ¹ ì‹¤ìˆ˜í•´ì„œ ê¹ì•„ë‚´ë¦¬ê¸°ë¥¼ ê±°ë“­í•˜ë©´ ì•ˆ ë˜ë¯€ë¡œ.\n",
      "Tuned model    : ì™•ì„ ë§Œì¡±ì‹œí‚¤ê¸° ìœ„í•´ ìë¦°ê³ ë¹„ì¸ ì¤„ê±°ë¦¬ê°€ ì•„ë‹Œ ê·¹ì ì¸ ìœ ë¨¸ë¥¼ ì„ì–´ì•¼ í–ˆê³ , ê·¸ë ‡ì§€ ì•Šìœ¼ë©´ ìƒëŒ€ë¥¼ ì˜ˆë¯¼í•˜ê²Œ ë§Œë“¤ ìœ„í—˜ì´ ìˆì—ˆë‹¤.\n",
      "------------------------------------------------------------\n",
      "[Sample 98]\n",
      "ì›ë¬¸            : That taco was bomb, amirite?\n",
      "ì´ˆì›”ë²ˆì—­(ì •ë‹µë°ì´í„°): ê·¸ íƒ€ì½” ì§„ì§œ ë§›ìˆì—ˆì§€, ë‚´ ë§ì´ ë§ì§€?\n",
      "base model     : ê·¸ íƒ€ì½” ì§„ì§œ ë§›ìˆì—ˆë‹¤, ë§ë§ì´ì•¼?\n",
      "Tuned model    : ê·¸ íƒ€ì½” ì§„ì§œ ë§›ìˆì—ˆë‹¤, ê°œê¿€í…œì´ë‹¤(ë‚´ë§ ë“¤ì—ˆëƒ?)/ë„¤ê°€ ë§í•´ì¤˜(ë°‘ëµˆì—¬)?\n",
      "------------------------------------------------------------\n",
      "[Sample 59]\n",
      "ì›ë¬¸            : Possibly more than anything else, this is Kim Jong Unâ€™s Achilles heel.\n",
      "ì´ˆì›”ë²ˆì—­(ì •ë‹µë°ì´í„°): ë¬´ì—‡ë³´ë‹¤ë„ ì´ê²ƒì´ ê¹€ì •ì€ì˜ ì•„í‚¬ë ˆìŠ¤ê±´ì¼ ìˆ˜ ìˆë‹¤.\n",
      "base model     : ì´ê±´ ê¹€ì •ì€ êµ­ë¬´ìœ„ì›ì¥ì˜ ì¹˜ëª…ì ì¸ ì•½ì ì´ ì•„ë‹ê¹Œ ì‹¶ë‹¤.\n",
      "Tuned model    : ì´ê±´ ê¹€ì •ì€ ì›ìˆ­ì´(ì–´ê·¸ë¡œ ëŒê¸° ì „ë¬¸ê°€)ì˜ ê°€ì¥ ì¹˜ëª…ì ì¸ ì•½ì ì¼ ê²ƒì´ë‹¤.\n",
      "------------------------------------------------------------\n",
      "[Sample 48]\n",
      "ì›ë¬¸            : She pulled a Cinderella story by completely transforming herself before the interview.\n",
      "ì´ˆì›”ë²ˆì—­(ì •ë‹µë°ì´í„°): ë©´ì ‘ ì „ì— ë¨¸ë¦¬ë¶€í„° ë°œëê¹Œì§€ ëª¨ë‘ ë°”ê¼‡ë”ë¼\n",
      "base model     : ì¸í„°ë·° ì „ì— ì™„ì „ ë³€í™”í•´ì„œ ë¹ˆë¯¼ê°€ ë”¸ë¡œ ë¹„ì£¼ì–¼ì„ ê°œì„ í–ˆë„¤.\n",
      "Tuned model    : ì¸í„°ë·° ì „ ìê¸° ë³€í™”í•´ì„œ ì‹ ë°ë ë¼ ì´ì•¼ê¸° ë§Œë“œë„¤.\n",
      "------------------------------------------------------------\n",
      "[Sample 50]\n",
      "ì›ë¬¸            : ...an obvious silver bullet that we can look to, to resolve it overnight.\n",
      "ì´ˆì›”ë²ˆì—­(ì •ë‹µë°ì´í„°): í•˜ë£»ë°¤ ìƒˆ ëª¨ë“  ê±¸ ë‹¨ë²ˆì— í’€ì–´ì¤„ ë§ŒëŠ¥ì¹˜íŠ¸í‚¤ ê°™ì€ í•´ë²•ì€ ì—†ë‹¤.\n",
      "base model     : ê±° ì‹¤ì† ìˆëŠ” ë°©ë²•(ëŒ€ì±…)ì´ê² ëŠ”ë°? í•˜ë£¨ ë§Œì— í•´ê²° ê°€ëŠ¥í•˜ê² ë„¤.\n",
      "Tuned model    : ê±° ê¸°ë‹¤ë¦¬ë‹¤ ì§€ì¹˜ì§€ë„ ë§ˆ, ì´ ë°©ë²•ì´ ë”± ë§ì•„ë–¨ì–´ì§ˆ ê±°ì•¼.\n",
      "------------------------------------------------------------\n",
      "[Sample 89]\n",
      "ì›ë¬¸            : He was throwing shade at you yesterday.\n",
      "ì´ˆì›”ë²ˆì—­(ì •ë‹µë°ì´í„°): ê±”ê°€ ë„ˆ ë’·ë‹´ê¹Œê³  ìˆì—ˆì–´.\n",
      "base model     : ì–´ì œ ë„ˆ ê¼¬ë¦¬ ë‚´ë¦¬ì§€ ëª» í•´ì„œ ìŸ¤ê°€ ì€ê·¼ìŠ¬ì© ë¹„ê¼¬ì•˜ì–´.\n",
      "Tuned model    : ë„ˆ ì–´ì œ ìŸ¤í•œí…Œ ë°œë ¸ì—ˆì§€(ìŸ¤ê°€ ë„ˆ ê¹Œë°œë ¸ì–´).\n",
      "------------------------------------------------------------\n",
      "[Sample 87]\n",
      "ì›ë¬¸            : You look nice today, no cap!\n",
      "ì´ˆì›”ë²ˆì—­(ì •ë‹µë°ì´í„°): ì˜¤ëŠ˜ ë„ˆ ì •ë§ ë©‹ì§€ë‹¤, ì§„ì§œë¡œ!\n",
      "base model     : ë„ˆ ì˜¤ëŠ˜ë”°ë¼ ì™„ì „ ì´ì˜ë‹¤(ì•ˆë…•)?\n",
      "Tuned model    : ë„ˆ ì˜¤ëŠ˜ë”°ë¼ ì™„ì „ ì´ì˜ë‹¤(ë‚¨ì ë§ì´ì•¼)!\n",
      "------------------------------------------------------------\n",
      "[Sample 46]\n",
      "ì›ë¬¸            : They acted like the Fourth of July over the tiniest bit of praise.\n",
      "ì´ˆì›”ë²ˆì—­(ì •ë‹µë°ì´í„°): ì¹­ì°¬ ì¡°ê¸ˆ ë“¤ì—ˆë‹¤ê³  ì–´ê¹¨ê°€ ë½• ì°¼ë˜ë¼\n",
      "base model     : ã„´ë¡€ ì¢€ ë¶€ë ¸ìœ¼ë©´ì„œ ì•„ì£¼ ê±´ë°©ì§€ê²Œ êµ´ì—ˆë„¤(ìƒì‚¬ë³‘ ê±¸ë¦¬ê² ì–´).\n",
      "Tuned model    : í•˜ëŠ” ê±° ë³´ë‹ˆ ì´ˆê³„ì ˆ(7ì›”)ì¸ë° ì•„ì£¼ ì‚´ì§ì˜ ì¹­ì°¬ì—ë„ ë‚œë¦¬ ë‚¬ë„¤.\n",
      "------------------------------------------------------------\n",
      "[Sample 38]\n",
      "ì›ë¬¸            : Heâ€™s the type who brings a knife to a gunfight and wonders why things go wrong.\n",
      "ì´ˆì›”ë²ˆì—­(ì •ë‹µë°ì´í„°): ì¤€ë¹„ë„ ì•ˆí•˜ê³  ë‡Œë¹„ìš°ê³  ë¤ë²¼ë“¤ì–´ ì™œ ë§í–ˆëŠ”ì§€ ëª¨ë¥´ëŠ” íƒ€ì…\n",
      "base model     : ê·¸ê±´ ë­”ê°€ ì˜ëª»ë˜ê¸° ì „ ì˜ˆë°© ì°¨ì›ìœ¼ë¡œ ì¹¼ì„ ì¤€ë¹„í•´ ë†“ëŠ” íƒ€ì…ì´ì•¼.\n",
      "Tuned model    : ê±”ëŠ” ëª©ìˆ¨ì„ ê±¸ê³  ìœ„í—˜ì„ ë¬´ë¦…ì“°ë©´ì„œë„ ì™œ ì¼ì´ ì˜ ì•ˆ í’€ë¦¬ëŠ”ì§€ì— ëŒ€í•´ ê¶ê¸ˆí•´í•´.\n",
      "------------------------------------------------------------\n",
      "[Sample 62]\n",
      "ì›ë¬¸            : There is a tide in the affairs of men... leads on to fortune.\n",
      "ì´ˆì›”ë²ˆì—­(ì •ë‹µë°ì´í„°): ë¬¼ë“¤ì–´ ì˜¬ë•Œ ë…¸ì €ì–´ì•¼ í•œë‹¤. \n",
      "base model     : good luck with your endeavors... ain't no such thing as a fool again.\n",
      "Tuned model    : ë§ºì–´ì§„ ë‚¨ë…€ ê´€ê³„ëŠ” ìš´ìˆ˜ ëŒ€ë°•ì´ì•¼(ê°‘ë¶„ì‹¸ ë°œìƒ).\n",
      "------------------------------------------------------------\n",
      "[Sample 95]\n",
      "ì›ë¬¸            : He's been a couch potato all weekend.\n",
      "ì´ˆì›”ë²ˆì—­(ì •ë‹µë°ì´í„°): ê·¸ ë‚¨ìëŠ” ì£¼ë§ ë‚´ë‚´ ì†ŒíŒŒì—ì„œ ì›€ì§ì´ì§ˆ ì•Šì•„.\n",
      "base model     : ì£¼ë§ ë‚´ë‚´ í™ˆìŠ¤ì¿¨ë§(í¸í•œ ìƒí™œ) í–ˆë„¤.\n",
      "Tuned model    : ì£¼ë§ ë‚´ë‚´ ê²Œì„ë§Œ í•˜ë‹¤ê°€(ì œìë¦¬ê±¸ìŒë§Œ í•˜ë‹¤) ëì–´.\n",
      "------------------------------------------------------------\n",
      "[Sample 65]\n",
      "ì›ë¬¸            : So we beat on, boats against the current, borne back ceaselessly...\n",
      "ì´ˆì›”ë²ˆì—­(ì •ë‹µë°ì´í„°): ìš°ë¦¬ëŠ” íŒŒë„ë¥¼ ê±°ìŠ¬ëŸ¬ ë…¸ ì €ì–´ë„, ëë‚´ ê³¼ê±°ë¡œ ë°€ë ¤ê°„ë‹¤.\n",
      "base model     : ê·¸ë˜ì„œ ìš°ë¦¬ëŠ” íŒŒë„ì— ë°€ë ¤ ê³„ì†ë˜ëŠ” ìœ ë°° ìƒí™œì„ ì§€ë‚¸ë‹¤...\n",
      "Tuned model    : ê·¸ë˜ì„œ ìš°ë¦¬ëŠ” íŒŒë„ë¥¼ ê±´ë„ˆ í˜„ì¬ì˜ í˜ì— ë¶€ë”ªíˆë©°,... ë‹¤ì‹œ ëŒì•„ì˜¨ë‹¤.\n",
      "------------------------------------------------------------\n",
      "[Sample 49]\n",
      "ì›ë¬¸            : He went full cowboy, jumping into the situation without a plan.\n",
      "ì´ˆì›”ë²ˆì—­(ì •ë‹µë°ì´í„°): ê³„íšë„ ì—†ì´ ë¬´ëŒ€ë½€ë¡œ ì§ˆë €ë”ë¼\n",
      "base model     : ê°‘ìê¸° ì™„ì „ í‘í™”í–ˆì–´(ì‚ëš¤ì–´ì§ˆ ì¤„ ëª°ëë„¤).\n",
      "Tuned model    : ã„±-ë³„ê²ƒë„ ì•ˆ í•˜ê³  ìƒí™© ì‹œì‘í•˜ë„¤(ì•„ë¬´ ê³„íš ì—†ë„¤).\n",
      "------------------------------------------------------------\n",
      "[Sample 61]\n",
      "ì›ë¬¸            : The lady doth protest too much, methinks.\n",
      "ì´ˆì›”ë²ˆì—­(ì •ë‹µë°ì´í„°): ì € ì—¬ìì˜ ê°•í•œ ë¶€ì •ì€ ê°•í•œ ê¸ì •ì¼ ìˆ˜ ìˆì§€,  ë” ìˆ˜ìƒí•œë°\n",
      "base model     : ê±” ë„ˆë¬´ ê·¹ë”œí•˜ë„¤, ì¢€ ìì œí•´ì•¼ í•´.\n",
      "Tuned model    : ì–˜ ì¢€ ê³¼í•˜ê²Œ ë°˜ëŒ€í•˜ëŠ” ê²ƒ ê°™ì•„(ì¶”ì¸¡), ë”´ ë° ë§¡ê²¨ë„ ë  ë“¯.\n",
      "------------------------------------------------------------\n",
      "[Sample 76]\n",
      "ì›ë¬¸            : Here's how it works, Meryl Streep.\n",
      "ì´ˆì›”ë²ˆì—­(ì •ë‹µë°ì´í„°): ì˜ ë“¤ì–´, ë°°ìš° ì–‘ë°˜.\n",
      "base model     : 9/10. ì™„ì „ ì©ë‹ˆë‹¤(ë§¤ë‹ˆì•„ê¸‰ ì¶”ì²œ).\n",
      "Tuned model    : 8/10, dude.\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from peft import PeftModel\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "\n",
    "\n",
    "# Base ëª¨ë¸ ë¡œë“œ\n",
    "base = AutoModelForCausalLM.from_pretrained(MODEL_ID, torch_dtype=torch.float32, trust_remote_code=True).to(device).eval()\n",
    "# Tuned ëª¨ë¸ ë¡œë“œ (Base + LoRA Adapter)\n",
    "tuned2 = PeftModel.from_pretrained(base, OUTPUT_DIR).to(device).eval()\n",
    "\n",
    "# 2. ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬\n",
    "file_path = \"test_data.csv\"\n",
    "df = pd.read_csv(file_path)\n",
    "\n",
    "# ì»¬ëŸ¼ëª… ë§¤í•‘\n",
    "test_df = df.rename(columns={\n",
    "    \"ì˜ì–´ ì›ë¬¸ (Source Text)\": \"input\",\n",
    "    \"ì´ˆì›” ë²ˆì—­\": \"output\"\n",
    "})\n",
    "\n",
    "# í…ŒìŠ¤íŠ¸í•  ìƒ˜í”Œ ê°œìˆ˜ ì„ íƒ (ëœë¤ 5ê°œ ë˜ëŠ” ì „ì²´)\n",
    "sampled_df = test_df.sample(25) # ì „ì²´ë¥¼ ë‹¤ ë³´ë ¤ë©´ test_df ì‚¬ìš©\n",
    "\n",
    "print(f\"ğŸ“Š í…ŒìŠ¤íŠ¸ ë°ì´í„°: ì´ {len(sampled_df)}ê°œ ìƒ˜í”Œë§\\n\")\n",
    "\n",
    "# 3. í”„ë¡¬í”„íŠ¸ ë° ìƒì„± í•¨ìˆ˜ ì„¤ì •\n",
    "SYSTEM_PROMPT = \"\"\"\n",
    "You are a professional translator who specializes in translating English slang and memes into Korean internet slang and trendy expressions.\n",
    "Your goal is to make the translation sound like a \"close friend\" or a \"Korean netizen\" speaking.\n",
    "\n",
    "**CRITICAL RULES:**\n",
    "1. **Never use polite language (Honorifics/Jon-dae-mal).** Use ONLY casual speech (Banmal).\n",
    "2. Do not translate literally. Use Korean slang, memes, and community vibes aggressively.\n",
    "3. If the original text is sarcastic or rude, preserve that tone perfectly.\n",
    "4. Output ONLY the Korean translation. No explanations.\n",
    "\"\"\"\n",
    "\n",
    "def build_test_prompt(input_text):\n",
    "    # í•™ìŠµ ë°ì´í„°ì™€ ë™ì¼í•œ ì˜ì–´ Instruction ì‚¬ìš©\n",
    "    instruction = \"Translate into Korean, but focus on cultural localization over literal meaning. Use trendy Korean internet slang and casual tone (Banmal) to match the vibe.\"\n",
    "\n",
    "    user_content = (\n",
    "        f\"ì§€ì‹œì‚¬í•­: {instruction}\\n\\n\"\n",
    "        f\"ì…ë ¥ ë¬¸ì¥: {input_text}\\n\"\n",
    "        f\"ì¶œë ¥ ì¡°ê±´: í•œêµ­ì–´ ë²ˆì—­ 1ê°œë§Œ ì¶œë ¥\"\n",
    "    )\n",
    "\n",
    "    return (\n",
    "        \"### System:\\n\" + SYSTEM_PROMPT.strip() + \"\\n\\n\"\n",
    "        \"### User:\\n\" + user_content + \"\\n\\n\"\n",
    "        \"### Assistant:\\ncompletion: \"\n",
    "    )\n",
    "\n",
    "@torch.no_grad()\n",
    "def generate(model, prompt):\n",
    "    inputs = tokenizer(prompt, return_tensors=\"pt\", truncation=True, max_length=2048).to(device)\n",
    "    out = model.generate(\n",
    "        **inputs,\n",
    "        max_new_tokens=128,\n",
    "        temperature=0.6,\n",
    "        top_p=0.9,\n",
    "        repetition_penalty=1.2,\n",
    "        do_sample=True,\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "        eos_token_id=tokenizer.eos_token_id\n",
    "    )\n",
    "    text = tokenizer.decode(out[0], skip_special_tokens=True)\n",
    "    if \"completion: \" in text:\n",
    "        return text.split(\"completion: \")[-1].strip()\n",
    "    elif \"### Assistant:\" in text:\n",
    "        return text.split(\"### Assistant:\")[-1].strip()\n",
    "    return text.strip()\n",
    "\n",
    "# 4. ì‹¤í–‰ ë° ê²°ê³¼ ì¶œë ¥ (ìš”ì²­í•˜ì‹  í¬ë§· ì ìš©)\n",
    "print(f\"{'='*20} [í…ŒìŠ¤íŠ¸ ê²°ê³¼ ë¹„êµ] {'='*20}\\n\")\n",
    "\n",
    "for idx, row in sampled_df.iterrows():\n",
    "    input_text = row['input']\n",
    "    ref_text = row['output']\n",
    "\n",
    "    prompt = build_test_prompt(input_text)\n",
    "\n",
    "    # ëª¨ë¸ ìƒì„±\n",
    "    base_out = generate(base, prompt)\n",
    "    tuned_out = generate(tuned2, prompt)\n",
    "\n",
    "    print(f\"[Sample {idx}]\")\n",
    "    print(f\"ì›ë¬¸            : {input_text}\")\n",
    "    print(f\"ì´ˆì›”ë²ˆì—­(ì •ë‹µë°ì´í„°): {ref_text}\")\n",
    "    print(f\"base model     : {base_out}\")\n",
    "    print(f\"Tuned model    : {tuned_out}\")\n",
    "    print(\"-\" * 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VupD98Nzs97q"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Apl0uKZsr1g"
   },
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
