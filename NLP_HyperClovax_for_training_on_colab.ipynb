{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8lBEaM4rZs6D",
    "outputId": "36b2fcea-6c47-4c28-dfc3-9c1edbef84b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: trl in /usr/local/lib/python3.12/dist-packages (0.26.1)\n",
      "Requirement already satisfied: sacrebleu in /usr/local/lib/python3.12/dist-packages (2.5.1)\n",
      "Requirement already satisfied: accelerate>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from trl) (1.12.0)\n",
      "Requirement already satisfied: datasets>=3.0.0 in /usr/local/lib/python3.12/dist-packages (from trl) (4.0.0)\n",
      "Requirement already satisfied: transformers>=4.56.1 in /usr/local/lib/python3.12/dist-packages (from trl) (4.57.3)\n",
      "Requirement already satisfied: portalocker in /usr/local/lib/python3.12/dist-packages (from sacrebleu) (3.2.0)\n",
      "Requirement already satisfied: regex in /usr/local/lib/python3.12/dist-packages (from sacrebleu) (2025.11.3)\n",
      "Requirement already satisfied: tabulate>=0.8.9 in /usr/local/lib/python3.12/dist-packages (from sacrebleu) (0.9.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.12/dist-packages (from sacrebleu) (2.0.2)\n",
      "Requirement already satisfied: colorama in /usr/local/lib/python3.12/dist-packages (from sacrebleu) (0.4.6)\n",
      "Requirement already satisfied: lxml in /usr/local/lib/python3.12/dist-packages (from sacrebleu) (6.0.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.12/dist-packages (from accelerate>=1.4.0->trl) (25.0)\n",
      "Requirement already satisfied: psutil in /usr/local/lib/python3.12/dist-packages (from accelerate>=1.4.0->trl) (5.9.5)\n",
      "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from accelerate>=1.4.0->trl) (6.0.3)\n",
      "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.12/dist-packages (from accelerate>=1.4.0->trl) (2.9.0+cu126)\n",
      "Requirement already satisfied: huggingface_hub>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from accelerate>=1.4.0->trl) (0.36.0)\n",
      "Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.12/dist-packages (from accelerate>=1.4.0->trl) (0.7.0)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from datasets>=3.0.0->trl) (3.20.0)\n",
      "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=3.0.0->trl) (18.1.0)\n",
      "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from datasets>=3.0.0->trl) (0.3.8)\n",
      "Requirement already satisfied: pandas in /usr/local/lib/python3.12/dist-packages (from datasets>=3.0.0->trl) (2.2.2)\n",
      "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.12/dist-packages (from datasets>=3.0.0->trl) (2.32.4)\n",
      "Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.12/dist-packages (from datasets>=3.0.0->trl) (4.67.1)\n",
      "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from datasets>=3.0.0->trl) (3.6.0)\n",
      "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.12/dist-packages (from datasets>=3.0.0->trl) (0.70.16)\n",
      "Requirement already satisfied: fsspec<=2025.3.0,>=2023.1.0 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (2025.3.0)\n",
      "Requirement already satisfied: tokenizers<=0.23.0,>=0.22.0 in /usr/local/lib/python3.12/dist-packages (from transformers>=4.56.1->trl) (0.22.1)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.12/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (3.13.2)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate>=1.4.0->trl) (4.15.0)\n",
      "Requirement already satisfied: hf-xet<2.0.0,>=1.1.3 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub>=0.21.0->accelerate>=1.4.0->trl) (1.2.0)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests>=2.32.2->datasets>=3.0.0->trl) (2025.11.12)\n",
      "Requirement already satisfied: setuptools in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (75.2.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (3.1.6)\n",
      "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (12.6.77)\n",
      "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.6.80 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (12.6.80)\n",
      "Requirement already satisfied: nvidia-cudnn-cu12==9.10.2.21 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (9.10.2.21)\n",
      "Requirement already satisfied: nvidia-cublas-cu12==12.6.4.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (12.6.4.1)\n",
      "Requirement already satisfied: nvidia-cufft-cu12==11.3.0.4 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (11.3.0.4)\n",
      "Requirement already satisfied: nvidia-curand-cu12==10.3.7.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (10.3.7.77)\n",
      "Requirement already satisfied: nvidia-cusolver-cu12==11.7.1.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (11.7.1.2)\n",
      "Requirement already satisfied: nvidia-cusparse-cu12==12.5.4.2 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (12.5.4.2)\n",
      "Requirement already satisfied: nvidia-cusparselt-cu12==0.7.1 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (0.7.1)\n",
      "Requirement already satisfied: nvidia-nccl-cu12==2.27.5 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (2.27.5)\n",
      "Requirement already satisfied: nvidia-nvshmem-cu12==3.3.20 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (3.3.20)\n",
      "Requirement already satisfied: nvidia-nvtx-cu12==12.6.77 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (12.6.77)\n",
      "Requirement already satisfied: nvidia-nvjitlink-cu12==12.6.85 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (12.6.85)\n",
      "Requirement already satisfied: nvidia-cufile-cu12==1.11.1.6 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (1.11.1.6)\n",
      "Requirement already satisfied: triton==3.5.0 in /usr/local/lib/python3.12/dist-packages (from torch>=2.0.0->accelerate>=1.4.0->trl) (3.5.0)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets>=3.0.0->trl) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets>=3.0.0->trl) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.12/dist-packages (from pandas->datasets>=3.0.0->trl) (2025.2)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (1.4.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (25.4.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (1.8.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (6.7.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (0.4.1)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets>=3.0.0->trl) (1.22.0)\n",
      "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.12/dist-packages (from python-dateutil>=2.8.2->pandas->datasets>=3.0.0->trl) (1.17.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.12/dist-packages (from sympy>=1.13.3->torch>=2.0.0->accelerate>=1.4.0->trl) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch>=2.0.0->accelerate>=1.4.0->trl) (3.0.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install trl sacrebleu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5jzRx1uWZQxI",
    "outputId": "1089814b-c84b-471c-e30b-2814bb4c06af"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n",
      "torch: 2.9.0+cu126\n",
      "trl: 0.26.1\n"
     ]
    }
   ],
   "source": [
    "import os, json, random\n",
    "from pathlib import Path\n",
    "from typing import Dict, Any, List\n",
    "\n",
    "import torch\n",
    "from datasets import Dataset\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "from peft import LoraConfig, PeftModel\n",
    "import trl\n",
    "from trl import SFTTrainer, SFTConfig\n",
    "import sacrebleu\n",
    "\n",
    "SEED = 42\n",
    "random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "\n",
    "os.environ.setdefault(\"PYTORCH_ENABLE_MPS_FALLBACK\", \"1\")\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "print(\"device:\", device)\n",
    "print(\"torch:\", torch.__version__)\n",
    "print(\"trl:\", trl.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "InqjDdXdZVM3",
    "outputId": "26ba2591-1188-4ff8-8248-cb01f1b52f8a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… ì „ì²´ í•™ìŠµ ë°ì´í„° ê°œìˆ˜: 600\n",
      "ì˜ˆì‹œ ë°ì´í„° í•­ëª© (ì²« ë²ˆì§¸):\n",
      "{'instruction': \"Don't translate it in Korean, but translate it according to Korean culture\", 'input': 'I actually saw him at the mall yesterday, no cap.', 'output': 'ë‚˜ ì–´ì œ ì‡¼í•‘ëª°ì—ì„œ ê±” ì§„ì§œë¡œ ë´¤ë‹¤ë‹ˆê¹Œ, êµ¬ë¼ ì•„ë‹˜.', 'term': 'No cap', 'meaning': \"ì§„ì§œì•¼, ê±°ì§“ë§ ì•„ë‹ˆì•¼ ('Cap'ì€ ê±°ì§“ë§ì„ ëœ»í•¨)\"}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "from datasets import Dataset\n",
    "\n",
    "DATA_PATH = Path(\"train_data.json\")\n",
    "\n",
    "# 1. ë°ì´í„° ë¡œë“œ\n",
    "text = DATA_PATH.read_text(encoding=\"utf-8\").strip()\n",
    "\n",
    "if not text:\n",
    "    raise RuntimeError(\"train_data.jsonì´ ë¹„ì–´ ìˆìŠµë‹ˆë‹¤.\")\n",
    "\n",
    "raw_data = []\n",
    "\n",
    "try:\n",
    "    # í•œ ì¤„ì”© ì½ê¸° (JSONL) ì‹œë„\n",
    "    for line in text.splitlines():\n",
    "        if line.strip():\n",
    "            raw_data.append(json.loads(line))\n",
    "except json.JSONDecodeError:\n",
    "    raw_data = json.loads(text)\n",
    "\n",
    "# 2. ë°ì´í„° ì •ì œ í•¨ìˆ˜\n",
    "def normalize_item(item: dict) -> dict:\n",
    "    # idiom ë”•ì…”ë„ˆë¦¬ì—ì„œ termê³¼ meaningì„ ì¶”ì¶œí•˜ì—¬ ìƒìœ„ ë ˆë²¨ë¡œ ì˜¬ë¦¼\n",
    "    idiom_data = item.get(\"idiom\", {})\n",
    "\n",
    "    return {\n",
    "        \"instruction\": item[\"instruction\"].strip(),\n",
    "        \"input\": item[\"input\"].strip(),\n",
    "        \"output\": item[\"output\"].strip(),\n",
    "        \"term\": idiom_data.get(\"term\", \"\").strip(),\n",
    "        \"meaning\": idiom_data.get(\"meaning\", \"\").strip()\n",
    "    }\n",
    "\n",
    "# 3. ë°ì´í„°ì…‹ ìƒì„±\n",
    "norm = [normalize_item(x) for x in raw_data]\n",
    "ds = Dataset.from_list(norm)\n",
    "\n",
    "print(f\"âœ… ì „ì²´ í•™ìŠµ ë°ì´í„° ê°œìˆ˜: {len(ds)}\")\n",
    "\n",
    "print(\"ì˜ˆì‹œ ë°ì´í„° í•­ëª© (ì²« ë²ˆì§¸):\")\n",
    "if len(ds) > 0:\n",
    "    print(ds[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 302,
     "referenced_widgets": [
      "93a284585c6f4ea0bb6d27bc6de26f48",
      "2a5df517c53049bd82492ca42ed4e756",
      "e46522da6e42449d929f88cb4d9674db",
      "4609d547ba014d4a8a291f358802e109",
      "8897576aecd74d08ac09ebfeb40eb8fa",
      "e64b91894c6647db924ea7eff3673255",
      "66bc5788568d4ffbb82fb09c78d3bf25",
      "d7f826877ca34377bfa694f3d682f84d",
      "7c233e0a539f4812956f4027cfee6c2d",
      "6fcc54fbe3384d65b09ad7920fc2491e",
      "9a0bd06d4d9b47d09a09a89e0c1da80f"
     ]
    },
    "id": "3qNZVVk9aBfE",
    "outputId": "5d62392f-7a1a-43b4-83d9-d31ad46c2d73"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93a284585c6f4ea0bb6d27bc6de26f48",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "### System:\n",
      "You are a professional translator who specializes in translating English slang and memes into Korean internet slang and trendy expressions.\n",
      "Your goal is to make the translation sound like a \"close friend\" or a \"Korean netizen\" speaking.\n",
      "\n",
      "**CRITICAL RULES:**\n",
      "1. **Never use polite language (Honorifics/Jon-dae-mal).** Use ONLY casual speech (Banmal).\n",
      "2. Do not translate literally. Use Korean slang, memes, and community vibes aggressively.\n",
      "3. If the original text is sarcastic or rude, preserve that tone perfectly.\n",
      "4. Output ONLY the Korean translation. No explanations.\n",
      "\n",
      "### User:\n",
      "ì§€ì‹œì‚¬í•­:\n",
      "completion: ë‚˜ ì–´ì œ ì‡¼í•‘ëª°ì—ì„œ ê±” ì§„ì§œë¡œ ë´¤ë‹¤ë‹ˆê¹Œ, êµ¬ë¼ ì•„ë‹˜.\n"
     ]
    }
   ],
   "source": [
    "from typing import Dict, Any\n",
    "\n",
    "SYSTEM_PROMPT = \"\"\"\n",
    "You are a professional translator who specializes in translating English slang and memes into Korean internet slang and trendy expressions.\n",
    "Your goal is to make the translation sound like a \"close friend\" or a \"Korean netizen\" speaking.\n",
    "\n",
    "**CRITICAL RULES:**\n",
    "1. **Never use polite language (Honorifics/Jon-dae-mal).** Use ONLY casual speech (Banmal).\n",
    "2. Do not translate literally. Use Korean slang, memes, and community vibes aggressively.\n",
    "3. If the original text is sarcastic or rude, preserve that tone perfectly.\n",
    "4. Output ONLY the Korean translation. No explanations.\n",
    "\"\"\"\n",
    "\n",
    "def build_prompt(example: Dict[str, Any]) -> str:\n",
    "    ref = \"\"\n",
    "    # termì´ë‚˜ meaningì´ ìˆëŠ” ê²½ìš°ì—ë§Œ ì°¸ê³  ì •ë³´ë¥¼ ì¶”ê°€\n",
    "    if example.get(\"term\") or example.get(\"meaning\"):\n",
    "        ref = f\"[Note]\\n- Expression: {example.get('term','')}\\n- Meaning: {example.get('meaning','')}\\n\\n\"\n",
    "\n",
    "    user = (\n",
    "        f\"ì§€ì‹œì‚¬í•­: {example['instruction']}\\n\\n\"\n",
    "        f\"{ref}\"\n",
    "        f\"ì…ë ¥ ë¬¸ì¥: {example['input']}\\n\"\n",
    "        f\"ì¶œë ¥ ì¡°ê±´: í•œêµ­ì–´ ë²ˆì—­ 1ê°œë§Œ ì¶œë ¥\"\n",
    "    )\n",
    "\n",
    "    return (\n",
    "        \"### System:\\n\"\n",
    "        f\"{SYSTEM_PROMPT.strip()}\\n\\n\"\n",
    "        \"### User:\\n\"\n",
    "        f\"{user}\\n\\n\"\n",
    "        \"### Assistant:\\n\"\n",
    "    )\n",
    "\n",
    "def to_prompt_completion(ex: Dict[str, Any]) -> Dict[str, str]:\n",
    "    return {\"prompt\": build_prompt(ex), \"completion\": ex[\"output\"]}\n",
    "\n",
    "# [ìˆ˜ì •ë¨] dsê°€ Dataset ê°ì²´ì´ë¯€ë¡œ [\"train\"] ì—†ì´ ë°”ë¡œ column_namesì— ì ‘ê·¼í•©ë‹ˆë‹¤.\n",
    "pc = ds.map(to_prompt_completion, remove_columns=ds.column_names)\n",
    "\n",
    "# [ìˆ˜ì •ë¨] ê²°ê³¼ í™•ì¸ ì‹œì—ë„ [\"train\"] í‚¤ ì—†ì´ ì¸ë±ìŠ¤ë¡œ ë°”ë¡œ ì ‘ê·¼í•©ë‹ˆë‹¤.\n",
    "print(pc[0][\"prompt\"][:600])\n",
    "print(\"completion:\", pc[0][\"completion\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MECAwn7NaDas",
    "outputId": "5953624f-c2ca-4949-ccae-5693ce31d104"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
      "âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "\n",
    "OUTPUT_DIR = \"/content/drive/MyDrive/V3_hyperclova-translator-mps\"\n",
    "MODEL_ID = \"naver-hyperclovax/HyperCLOVAX-SEED-Text-Instruct-0.5B\"\n",
    "\n",
    "# 1. í† í¬ë‚˜ì´ì € ë¡œë“œ\n",
    "tokenizer = AutoTokenizer.from_pretrained(MODEL_ID, trust_remote_code=True)\n",
    "tokenizer.padding_side = \"right\"\n",
    "if tokenizer.pad_token is None:\n",
    "    tokenizer.pad_token = tokenizer.eos_token\n",
    "\n",
    "base_model = AutoModelForCausalLM.from_pretrained(\n",
    "    MODEL_ID,\n",
    "    torch_dtype=torch.float16,  # MPS ì•ˆì •ì„±\n",
    "    trust_remote_code=True,\n",
    "    device_map=\"auto\"\n",
    ")\n",
    "base_model.config.use_cache = False\n",
    "print(\"âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 258,
     "referenced_widgets": [
      "138c82497b874844b7091bfb01cdb235",
      "7c286b8183704b3f9f26c1ae042a0090",
      "92404ffff93d49cf9cdd6a88ffc4f690",
      "c183fee9498848fd938a8fc5f96e0e83",
      "8d5b586ae2eb420f841ebc0e776793a5",
      "56a0ddcb3cb8420fbb982bdb72351f6e",
      "7b6afe6076f54e769d99bfe2b3e5bff1",
      "48d5835cb99641c888f85ef95b7eaee1",
      "d28c9b0a12ce4ba2ba10d2dad2b42e54",
      "06ffbeed34404005baf3b066b2354291",
      "d1ccd1006e8e4969b9e8d0833d137829",
      "24cafce1e74c4f0c8f08787a65fcef02",
      "93dd241643ca4ac896e5f33d284fdaba",
      "3eac2973d1864fa09f7dbd1a6ca79dc5",
      "130714dcbf3c489a903a7dd41c0073e8",
      "42f01963a1464071b173f8fb61a8762e",
      "a61d3b7ee53a4188a82be6c3495a290d",
      "e383c5bc406a4d299e12ee7d5e081c90",
      "a49df6dcef5346ebaf4ab7f5336bb77f",
      "b05e3f0875be48f393154c6f810f0bf0",
      "af043ba561c045df97030a451ffb3e0c",
      "344b1650950040acbffba1b636cded5f",
      "dcb97af31f76457481a39195fddb482a",
      "d51cf0c593824e468628ca39ff6de835",
      "7a4c3181982e4604a09c9e0f88b6e07a",
      "abe30884186e4d6ca871cee41890d9c0",
      "690760066194411f8539e4a7a187304e",
      "bfd7b8dc76994d4ead3b60298d5218c0",
      "286f87d7baaf4e3eaacdfbb97e466ec1",
      "fa10d98232a5481fb65f3961f00fe0ba",
      "f49c723255d24f1488c316433b397231",
      "ae083eb9804d4a12b871d03fd1d0b56b",
      "0e4c8705e35e4bd4bf1397f1554b5f8a"
     ]
    },
    "id": "-ef6PUJDaFn8",
    "outputId": "fbd60fd4-0c6d-4705-95fe-b9e2648f4b06"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… target_modules: ['q_proj', 'k_proj', 'v_proj', 'o_proj', 'gate_proj', 'up_proj', 'down_proj']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.12/dist-packages/peft/mapping_func.py:72: UserWarning: You are trying to modify a model with PEFT for a second time. If you want to reload the model with a different config, make sure to call `.unload()` before.\n",
      "  warnings.warn(\n",
      "/usr/local/lib/python3.12/dist-packages/peft/tuners/tuners_utils.py:282: UserWarning: Already found a `peft_config` attribute in the model. This will lead to having multiple adapters in the model. Make sure to know what you are doing!\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "138c82497b874844b7091bfb01cdb235",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Adding EOS to train dataset:   0%|          | 0/600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24cafce1e74c4f0c8f08787a65fcef02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Tokenizing train dataset:   0%|          | 0/600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dcb97af31f76457481a39195fddb482a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Truncating train dataset:   0%|          | 0/600 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The model is already on multiple devices. Skipping the move to device specified in `args`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… trainer ì¤€ë¹„ ì™„ë£Œ\n"
     ]
    }
   ],
   "source": [
    "preferred_targets = [\"q_proj\",\"k_proj\",\"v_proj\",\"o_proj\",\"gate_proj\",\"up_proj\",\"down_proj\"]\n",
    "\n",
    "def guess_target_modules(model) -> List[str]:\n",
    "    names = set()\n",
    "    for n,_ in model.named_modules():\n",
    "        names.add(n.split(\".\")[-1])\n",
    "    return [t for t in preferred_targets if t in names]\n",
    "\n",
    "targets = guess_target_modules(base_model)\n",
    "if not targets:\n",
    "    targets = \"all-linear\"\n",
    "    print(\"âš ï¸ target_modules ìë™ íƒì§€ ì‹¤íŒ¨ â†’ all-linear ì‚¬ìš©\")\n",
    "else:\n",
    "    print(\"âœ… target_modules:\", targets)\n",
    "\n",
    "peft_config = LoraConfig(\n",
    "    r=32,\n",
    "    lora_alpha=64,\n",
    "    lora_dropout=0.05,\n",
    "    target_modules=targets,\n",
    "    bias=\"none\",\n",
    "    task_type=\"CAUSAL_LM\",\n",
    ")\n",
    "\n",
    "training_args = SFTConfig(\n",
    "    output_dir=OUTPUT_DIR,\n",
    "    num_train_epochs=10,\n",
    "    per_device_train_batch_size=2,\n",
    "    gradient_accumulation_steps=4,\n",
    "    learning_rate=1e-4,\n",
    "    lr_scheduler_type=\"cosine\",\n",
    "    warmup_ratio=0.1,\n",
    "    logging_steps=50,\n",
    "    eval_strategy=\"no\",\n",
    "    #eval_steps=50,\n",
    "    save_strategy=\"steps\",\n",
    "    save_steps=200,\n",
    "    bf16=False,\n",
    "    fp16=True,\n",
    "    optim =\"adamw_torch\",\n",
    "    report_to=\"none\",\n",
    "    packing=False,\n",
    "    seed=SEED,\n",
    "    completion_only_loss=True,\n",
    "    dataset_text_field=\"text\",\n",
    ")\n",
    "\n",
    "trainer = SFTTrainer(\n",
    "    model=base_model,\n",
    "    args=training_args,\n",
    "    train_dataset=pc,\n",
    "    peft_config=peft_config,\n",
    ")\n",
    "\n",
    "print(\"âœ… trainer ì¤€ë¹„ ì™„ë£Œ\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 599
    },
    "id": "pYEbjN5OaKt8",
    "outputId": "dadf5a37-6bf3-4fa8-b6c1-5fdefe652f14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ í•™ìŠµ ì‹œì‘\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='750' max='750' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [750/750 18:13, Epoch 10/10]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>2.799500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>1.813600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>1.603400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.940300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.652100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.429000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.163900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.136800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.069200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.026900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.019900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.011700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.007800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>0.007200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>750</td>\n",
       "      <td>0.007200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… í•™ìŠµ ì¢…ë£Œ\n",
      "ğŸ‰ ì €ì¥ ì™„ë£Œ: /content/drive/MyDrive/V3_hyperclova-translator-mps\n"
     ]
    }
   ],
   "source": [
    "print(\"ğŸš€ í•™ìŠµ ì‹œì‘\")\n",
    "trainer.train()\n",
    "print(\"âœ… í•™ìŠµ ì¢…ë£Œ\")\n",
    "\n",
    "trainer.model.save_pretrained(OUTPUT_DIR)\n",
    "tokenizer.save_pretrained(OUTPUT_DIR)\n",
    "print(f\"ğŸ‰ ì €ì¥ ì™„ë£Œ: {OUTPUT_DIR}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vNhTMyM2kQaj",
    "outputId": "9a961182-241d-474d-d92d-8372b82d9fa6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ì´ë™ ì™„ë£Œ: /content/drive/MyDrive/my_lab_folder\n"
     ]
    }
   ],
   "source": [
    "import shutil\n",
    "import os\n",
    "\n",
    "source = '/content/V3_hyperclova-translator-mps' # ì˜®ê¸¸ í´ë” ì´ë¦„\n",
    "destination = '/content/drive/MyDrive/my_lab_folder' # ë“œë¼ì´ë¸Œ ë‚´ ì €ì¥í•  ê²½ë¡œ\n",
    "\n",
    "# í´ë” ì´ë™ ì‹¤í–‰\n",
    "try:\n",
    "    shutil.move(source, destination)\n",
    "    print(f\"ì´ë™ ì™„ë£Œ: {destination}\")\n",
    "except Exception as e:\n",
    "    print(f\"ì˜¤ë¥˜ ë°œìƒ: {e}\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
